{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brief Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stacking is a technique that is popular in machine learning competitions and real-world problems where even small gain in performance is important. Stacking collects predictions made by several models and then runs another model on top of them. This results in ability to pick insights from multiple approaches and combine them.\n",
    "\n",
    "In this notebook, an implementation of stacking is demonstrated. This implementation has three noteworthy properties:\n",
    "\n",
    "1. final model uses out-of-fold predictions of base models and this reduces impact of predictions that are made by high-capacity models, i.e., models that are prone to overfit;\n",
    "\n",
    "2. `StackingRegressor` and `StackingClassifier` fully support `sklearn` API which means that, for example, `GridSearchCV` can be used with them;\n",
    "\n",
    "3. all estimators with `sklearn` API are supported as both first stage or second stage estimators; in particular, objects of class `sklearn.pipeline.Pipeline` are supported."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An easy-to-read guide to stacking and some other ensembling techniques:\n",
    "* [https://mlwave.com/kaggle-ensembling-guide/](https://mlwave.com/kaggle-ensembling-guide/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The article where stacking was suggested at the first time:\n",
    "* Wolpert, D. (1992). Stacked generalization, Neural Networks (5) : 241–259."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from dsawl.stacking import StackingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Illustrative Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bunch = load_boston()\n",
    "X, y = bunch.data, bunch.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=361)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarks Produced by Single Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77601926508014896"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regression = LinearRegression().fit(X_train, y_train)\n",
    "linear_regression_predictions = linear_regression.predict(X_test)\n",
    "r2_score(y_test, linear_regression_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65217359563067423"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_neighbors = KNeighborsRegressor(n_neighbors=3).fit(X_train, y_train)\n",
    "k_neighbors_predictions = k_neighbors.predict(X_test)\n",
    "r2_score(y_test, k_neighbors_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91034904977352005"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest = RandomForestRegressor(random_state=361).fit(X_train, y_train)\n",
    "random_forest_predictions = random_forest.predict(X_test)\n",
    "r2_score(y_test, random_forest_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking Itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92254428978438108"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacking = StackingRegressor(\n",
    "    base_estimators_types=[LinearRegression, KNeighborsRegressor, RandomForestRegressor],\n",
    "    base_estimators_params=[{}, {'n_neighbors': 3}, {}],\n",
    "    random_state=361\n",
    ")\n",
    "stacking.fit(X_train, y_train)\n",
    "stacking_predictions = stacking.predict(X_test)\n",
    "r2_score(y_test, stacking_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although linear regression and method of $K$ nearest neighbors are significantly weaker than random forest in the problem under consideration, involvement of their predictions leads to a moderate increase in $R^2$ coefficient of determination. This illustrates why stacking can be powerful sometimes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Be Continued"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need more examples of how to use `StackingRegressor` or `StackingClassifier` and you can not wait until this demo is updated, please look at the file located at `../tests/stacking_tests.py`. Also you can call Python's built-in function `help` with a class or a methods as its argument — all classes and public methods from `dsawl` package are documented."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsawl_env",
   "language": "python",
   "name": "dsawl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
