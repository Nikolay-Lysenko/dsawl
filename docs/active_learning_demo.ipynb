{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brief Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, one can find answers to the following questions:\n",
    "* What active learning is?\n",
    "* How to use implementations of active learning strategies from `dsawl` package?\n",
    "* How do $\\varepsilon$-greedy active learning perform relatively random selection?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* An article that contains review of approaches to active learning: [Yang, 2017](https://arxiv.org/pdf/1702.08540.pdf);\n",
    "* An article about EG-Active algorithm: [Bouneffouf, 2014](https://arxiv.org/abs/1408.2196)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from copy import copy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from dsawl.active_learning.pool_based_sampling import EpsilonGreedyPickerFromPool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook-level Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(361)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User-defined Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# It is not a good practice to store binary files\n",
    "# (like PNG images) in a Git repository, but for\n",
    "# your local use you can set it to `True`.\n",
    "draw_plots = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active Learning Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active learning setup assumes that, given a model and a training set,\n",
      "it is possible to extend the training set with new labelled examples\n",
      "and the goal is to do it with maximum possible improvement of model\n",
      "quality subject to constraint on how many new examples can be added.\n",
      "Further, pool-bases sampling means that new examples come from\n",
      "a fixed and known set of initially unlabelled examples, i.e., the task\n",
      "is to choose objects to be studied, not to synthesize them arbitrarily.\n"
     ]
    }
   ],
   "source": [
    "# Extract necessary info from docstring\n",
    "# in order to avoid copying and pasting.\n",
    "import dsawl.active_learning.pool_based_sampling as pbs\n",
    "print(pbs.__doc__.split('\\n\\n')[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a dataset that is involved in further examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dimensionality = 2\n",
    "lower_bound = -2\n",
    "upper_bound = 2\n",
    "pool_size = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_initial = np.array(\n",
    "    [[1, -1],\n",
    "     [2, -2],\n",
    "     [3, -3],\n",
    "     [-1, -1],\n",
    "     [-2, -2],\n",
    "     [-3, -3],\n",
    "     [0, 1],\n",
    "     [0, 2],\n",
    "     [0, 3]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_new = np.random.uniform(\n",
    "    lower_bound, upper_bound, size=(pool_size, dimensionality)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_hold_out = np.random.uniform(\n",
    "    lower_bound, upper_bound, size=(pool_size, dimensionality)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_target(X: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute class label for a simple classification problem where\n",
    "    2D plane is split into three regions by rays such that they\n",
    "    start from the origin and an angle between any pair of them\n",
    "    has 120 degrees.\n",
    "    \n",
    "    :param X:\n",
    "        coordinates of points from the plane\n",
    "    :return:\n",
    "        labels of regions where points are located\n",
    "    \"\"\"\n",
    "    \n",
    "    def compute_target_for_row(x: np.ndarray) -> int:\n",
    "        if x[0] > 0:\n",
    "            return 1 if x[1] - math.tan(math.radians(30)) * x[0] > 0 else 2\n",
    "        else:\n",
    "            return 1 if x[1] + math.tan(math.radians(30)) * x[0] > 0 else 3\n",
    "        \n",
    "    y = np.apply_along_axis(compute_target_for_row, axis=1, arr=X)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_initial = compute_target(X_train_initial)\n",
    "y_new = compute_target(X_new)\n",
    "y_hold_out = compute_target(X_hold_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if draw_plots:\n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "    ax = fig.add_subplot(111)\n",
    "    for label, color in zip(range(1, 4), ['b', 'r', 'g']):\n",
    "        curr_X = X_train_initial[y_train_initial == label, :]\n",
    "        ax.scatter(curr_X[:, 0], curr_X[:, 1], c=color, marker='D')\n",
    "    for label, color in zip(range(1, 4), ['b', 'r', 'g']):\n",
    "        curr_X = X_new[y_new == label, :]\n",
    "        ax.scatter(curr_X[:, 0], curr_X[:, 1], c=color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step-by-Step Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instances of `EpsilonGreedyPickerFromPool` have two initialization arguments: `scorer` and `exploration_probability`. Let us discuss both of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Argument named `scorer` defines an internal entity that ranks new objects by usefullness of their labels. The higher the rank, the more valuable a label of an object is. As for technical implementation, all scorers are instances of classes that inherit from these one class:\n",
    "`dsawl.active_learning.pool_based_sampling.BaseScorer`.\n",
    "\n",
    "Any instance that satisfies above condition can be passed as `scorer`. However, the easiest and the safest way to pass value of `scorer` is to pass a string that can be recognized as a name of pre-defined scorer.\n",
    "\n",
    "For classification, supported strings are:\n",
    "* 'confidence' — the $i$-th object has score $\\max_{j} \\hat{p}_{ij}$ where $\\hat{p}_{ij}$ is estimated (predicted) probability that the $i$-th object is an object of $j$-th class;\n",
    "* 'margin'  — the $i$-th object has score $\\max_{j} \\hat{p}_{ij} - \\max_{j \\ne \\hat{y}_i} \\hat{p}_{ij}$ where $\\hat{y}_i$ is predicted class of the $i$-th object, i.e., $\\hat{y}_i = \\arg \\max {j} \\hat{p}_{ij}$;\n",
    "* 'entropy' — the $i$-th object has score $\\sum_{j} \\hat{p}_{ij} \\log \\hat{p}_{ij}$;\n",
    "* 'divergence' — the $i$-th object has score $\\sum_{k}D_{KL}(\\hat{p}_{ijk} \\, \\Vert \\, \\overline{p}_{ij})$ where there is a committee (i.e., list) of classifiers indiced by $k$, $\\hat{p}_{ijk}$ is predicted by the $k$-th classifier probability that the $i$-th object is an object of $j$-th class, $\\overline{p}_{ij}$ is the average of all $\\hat{p}_{ijk}$ over $k$, and $D_{KL}$ is Kullback-Leibler divergence between $\\hat{p}_{ijk}$ and $\\overline{p}_{ij}$ (both are considered to be distributions of class label $j$).\n",
    "\n",
    "For regression, supported strings are:\n",
    "* 'predictions_variance' — the $i$-th object has score $\\mathrm{Var}_k \\hat{y}_{ik}$ where there is a committee of regressors indiced by $k$ and $\\hat{y}_{ik}$ is predicted by the $k$-th regressor target value for the $i$-th object;\n",
    "* 'target_variance' — the $i$-th object has score that is equal to an estimate of target's variance on it: $\\max(\\hat{y^2}_i - \\hat{y}_i^2, 0)$ where there is a pair of regressors and the first one predicts target itself, whereas the second one predicts squared target.\n",
    "\n",
    "All of the above strings define scoring function, but do not define tools of a scorer. Here the word 'tools' means a classifier, a pair of regressors, or a committee of classifiers or regressors. Such tools must be passed explicitly. It can be done either with `set_tools` method (properly trained tools are required) or with `update_tools` method (just one estimator is needed, but training data must be provided too).\n",
    "\n",
    "Below cells illustrate how to pass `scorer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "picker = EpsilonGreedyPickerFromPool(scorer='margin')\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train_initial, y_train_initial)\n",
    "picker.set_tools(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "picker = EpsilonGreedyPickerFromPool(scorer='margin')\n",
    "picker.update_tools(X_train_initial, y_train_initial, RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, go to `exploration_probability` argument. It can be either float or a list of floats. If it is a float, it produces no problem in a short run, but if there are lots of calls, it is better to start with high exploration probability and then decrease it gradually. List of float as `exploration_probability` allows doing so, but also it imposes a limitation on total number of calls — it can not be higher than the length of the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "picker = EpsilonGreedyPickerFromPool(scorer='margin', exploration_probability=[0.5, 0.4, 0.3, 0.2, 0.1])\n",
    "picker.update_tools(X_train_initial, y_train_initial, RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usage of a created instance is as simple as the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.06107047, -1.73046259],\n",
       "       [-0.50815302,  0.92325141],\n",
       "       [-0.2172508 , -1.24209527]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = picker.pick_new_objects(X_new, n_to_pick=3)\n",
    "X_new[indices, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Illustrative End-to-End Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here $\\varepsilon$-greedy strategy is compared with a benchmark based on random selection from a pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=20, random_state=361)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_n_points_to_explore = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epsilon = 0.1\n",
    "scorer = 'margin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def report_accuracy_of_benchmark(\n",
    "        n_new_points: int,\n",
    "        clf: BaseEstimator,\n",
    "        X_train_initial: np.ndarray, y_train_inital: np.ndarray,\n",
    "        X_new: np.ndarray, y_new: np.ndarray,\n",
    "        X_hold_out: np.ndarray, y_hold_out: np.ndarray\n",
    "        ) -> float:\n",
    "    \"\"\"\n",
    "    Compute accuracy of approach where `n_new_points` objects\n",
    "    are picked from a pool at random, without active learning.\n",
    "    \"\"\"\n",
    "    X_train = np.vstack((X_train_initial, X_new[:n_new_points, :]))\n",
    "    y_train = np.hstack((y_train_initial, y_new[:n_new_points]))\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_hold_out_hat = clf.predict(X_hold_out)\n",
    "    return accuracy_score(y_hold_out, y_hold_out_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def report_accuracy_of_epsilon_greedy_strategy(\n",
    "        n_new_points: int,\n",
    "        clf: BaseEstimator,\n",
    "        epsilon: float,\n",
    "        scorer: str,\n",
    "        X_train_initial: np.ndarray, y_train_inital: np.ndarray,\n",
    "        X_new: np.ndarray, y_new: np.ndarray,\n",
    "        X_hold_out: np.ndarray, y_hold_out: np.ndarray\n",
    "        ) -> float:\n",
    "    \"\"\"\n",
    "    Compute accuracy of epsilon-greedy approach to active\n",
    "    learning.\n",
    "    \"\"\"\n",
    "    X_train = copy(X_train_initial)\n",
    "    y_train = copy(y_train_inital)\n",
    "    clf.fit(X_train, y_train)\n",
    "    picker = EpsilonGreedyPickerFromPool(\n",
    "        scorer, exploration_probability=epsilon\n",
    "    )\n",
    "    picker.set_tools(clf)\n",
    "    for i in range(n_new_points):\n",
    "        indices = picker.pick_new_objects(X_new, n_to_pick=1)\n",
    "        X_train = np.vstack((X_train, X_new[indices, :]))\n",
    "        y_train = np.hstack((y_train, y_new[indices]))\n",
    "        picker.update_tools(X_train, y_train)\n",
    "        X_new = np.delete(X_new, indices, axis=0)\n",
    "        y_new = np.delete(y_new, indices)\n",
    "    clf = picker.get_tools()\n",
    "    y_hold_out_hat = clf.predict(X_hold_out)\n",
    "    return accuracy_score(y_hold_out, y_hold_out_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93.703333333333276"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_scores = [\n",
    "    report_accuracy_of_benchmark(\n",
    "        n, clf,\n",
    "        X_train_initial, y_train_initial, X_new, y_new,\n",
    "        X_hold_out, y_hold_out\n",
    "    )\n",
    "    for n in range(1, max_n_points_to_explore + 1)\n",
    "]\n",
    "sum(benchmark_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96.056666666666743"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epsilon_greedy_scores = [\n",
    "    report_accuracy_of_epsilon_greedy_strategy(\n",
    "        n, clf, epsilon, scorer,\n",
    "        X_train_initial, y_train_initial, X_new, y_new,\n",
    "        X_hold_out, y_hold_out\n",
    "    )\n",
    "    for n in range(1, max_n_points_to_explore + 1)\n",
    "]\n",
    "sum(epsilon_greedy_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if draw_plots:\n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(benchmark_scores)\n",
    "    ax.plot(epsilon_greedy_scores, c='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To conclude, it can be seen that there is a gain from usage active learning instead of selecting objects randomly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsawl_env",
   "language": "python",
   "name": "dsawl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
