{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brief Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is a training set something immutable and unexpandable? Active learning relates to situations where the answer is no. The training set size can be increased, but, of course, labelling of new examples is not costless.\n",
    "\n",
    "Pool-based setup of active learning assumes that, given a model and a training set, there is also a fixed and known $n$-element set of initially unlabelled examples and the goal is to select $k$, $k < n$, examples from there such that disclosure of their target variables produces the most significant impact on model quality.\n",
    "\n",
    "There are other setups of active learning problems as well (e.g., how to synthesize feature representations of objects to be studied), but all of them are beyond the scope of this demo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, one can find answers to the following questions:\n",
    "* How to use implementations of active learning strategies from `dsawl` package?\n",
    "* How do $\\varepsilon$-greedy active learning perform relatively random selection?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* An article that contains review of approaches to active learning: [Yang, 2017](https://arxiv.org/pdf/1702.08540.pdf);\n",
    "* An article about EG-Active algorithm: [Bouneffouf, 2014](https://arxiv.org/abs/1408.2196)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from copy import copy\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "from dsawl.active_learning.pool_based_sampling import CombinedSamplerFromPool\n",
    "from dsawl.active_learning.utils import make_committee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook-level Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(361)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User-defined Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# It is not a good practice to store binary files\n",
    "# (like PNG images) in a Git repository, but for\n",
    "# your local use you can set it to `True`.\n",
    "draw_plots = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, a synthetic dataset that is used by further examples is created. You can skip details of this section if you are interested only in user interface of active learning utilities. If this is the case, go to \"Step-by-Step Tutorial\" section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dimensionality = 2\n",
    "lower_bound = -2\n",
    "upper_bound = 2\n",
    "pool_size = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_initial = np.array(\n",
    "    [[1, -1],\n",
    "     [2, -2],\n",
    "     [3, -3],\n",
    "     [-1, -1],\n",
    "     [-2, -2],\n",
    "     [-3, -3],\n",
    "     [0, 1],\n",
    "     [0, 2],\n",
    "     [0, 3]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_new = np.random.uniform(\n",
    "    lower_bound, upper_bound, size=(pool_size, dimensionality)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_hold_out = np.random.uniform(\n",
    "    lower_bound, upper_bound, size=(pool_size, dimensionality)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_target(X: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute class label for a simple classification problem where\n",
    "    2D plane is split into three regions by rays such that they\n",
    "    start from the origin and an angle between any pair of them\n",
    "    has 120 degrees.\n",
    "    \n",
    "    :param X:\n",
    "        coordinates of points from the plane\n",
    "    :return:\n",
    "        labels of regions where points are located\n",
    "    \"\"\"\n",
    "    \n",
    "    def compute_target_for_row(x: np.ndarray) -> int:\n",
    "        if x[0] > 0:\n",
    "            return 1 if x[1] - math.tan(math.radians(30)) * x[0] > 0 else 2\n",
    "        else:\n",
    "            return 1 if x[1] + math.tan(math.radians(30)) * x[0] > 0 else 3\n",
    "        \n",
    "    y = np.apply_along_axis(compute_target_for_row, axis=1, arr=X)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_initial = compute_target(X_train_initial)\n",
    "y_new = compute_target(X_new)\n",
    "y_hold_out = compute_target(X_hold_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if draw_plots:\n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "    ax = fig.add_subplot(111)\n",
    "    for label, color in zip(range(1, 4), ['b', 'r', 'g']):\n",
    "        curr_X = X_train_initial[y_train_initial == label, :]\n",
    "        ax.scatter(curr_X[:, 0], curr_X[:, 1], c=color, marker='D')\n",
    "    for label, color in zip(range(1, 4), ['b', 'r', 'g']):\n",
    "        curr_X = X_new[y_new == label, :]\n",
    "        ax.scatter(curr_X[:, 0], curr_X[:, 1], c=color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step-by-Step Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As of now, the most convenient and comprehensive user interface is provided by `CombinedSamplerFromPool` class. Its instances can exploit accumulated knowledge about decision boundary of the model and can make exploratory actions. Various approaches to exploitation and exploration are supported."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class `CombinedSamplerFromPool` have two initialization arguments: `scorers` and `scorers_probabilities`. Let us discuss both of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An argument named `scorers`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An argument named `scorers` defines a list of internal entities that rank new objects by usefullness of their labels. The more valuable a label of an object is, the higher the rank should be. As for technical implementation, all scoring entities are instances of classes that inherit from these one class:\n",
    "`dsawl.active_learning.pool_based_sampling.BaseScorer`.\n",
    "\n",
    "Any instance that satisfies the above condition can be an element of `scorers`. However, the easiest and the safest way to pass value of `scorers` is to pass list of strings that can be recognized as a names of pre-defined scorers.\n",
    "\n",
    "If it is a classification problem, supported strings are:\n",
    "* 'confidence' — the $i$-th object has score $-(\\max_{j} \\hat{p}_{ij})$ where $\\hat{p}_{ij}$ is estimated (predicted) probability that the $i$-th object is an object of $j$-th class;\n",
    "* 'margin'  — the $i$-th object has score $-(\\max_{j} \\hat{p}_{ij} - \\max_{j \\ne \\hat{y}_i} \\hat{p}_{ij})$ where $\\hat{y}_i$ is predicted class of the $i$-th object, i.e., $\\hat{y}_i = \\arg \\max_{j} \\hat{p}_{ij}$;\n",
    "* 'entropy' — the $i$-th object has score $\\sum_{j} \\hat{p}_{ij} \\log \\hat{p}_{ij}$;\n",
    "* 'divergence' — the $i$-th object has score $\\sum_{k}D_{KL}(\\hat{p}_{ijk} \\, \\Vert \\, \\overline{p}_{ij})$ where there is a committee (i.e., list) of classifiers indiced by $k$, $\\hat{p}_{ijk}$ is predicted by the $k$-th classifier probability that the $i$-th object is an object of $j$-th class, $\\overline{p}_{ij}$ is the average of all $\\hat{p}_{ijk}$ over $k$, and $D_{KL}$ is Kullback-Leibler divergence between $\\hat{p}_{ijk}$ and $\\overline{p}_{ij}$ (both $\\hat{p}_{ijk}$ and $\\overline{p}_{ij}$ are considered to be distributions of class label $j$).\n",
    "\n",
    "Note that for a binary classification problem, the first three options result in the same ranking.\n",
    "\n",
    "If it is a regression problem, supported strings are:\n",
    "* 'predictions_variance' — the $i$-th object has score $\\mathrm{Var}_k \\hat{y}_{ik}$ where there is a committee of regressors indiced by $k$ and $\\hat{y}_{ik}$ is predicted by the $k$-th regressor target value for the $i$-th object;\n",
    "* 'target_variance' — the $i$-th object has score that is equal to an estimate of target's variance at it: $\\max(\\hat{y^2}_i - \\hat{y}_i^2, 0)$ where there is a pair of regressors and the first one predicts target itself, whereas the second one predicts squared target.\n",
    "\n",
    "Finally, there are two strings for making exploratory actions:\n",
    "* 'random' — all objects are ranked randomly;\n",
    "* 'density' — the $i$-th object has score equal to negative logarithm of estimated density of data distribution at the corresponding to the $i$-th object point; such scoring is designed for outliers exploration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the above strings define scoring function, but do not define tools of scorers. The meaning of the word 'tools' depends on subclass of `BaseScorer` class:\n",
    "* if a string is 'confidence', 'margin', or 'entropy', tools are a classifier;\n",
    "* if a string is 'divergence', tools are a committee of classifiers;\n",
    "* if a string is 'predictions_variance', tools are a committee of regressors;\n",
    "* if a string is 'target_variance', tools are a pair of regressors;\n",
    "* if a string is 'random', tools are `None`;\n",
    "* if a string is 'density', tools are a density estimator (such as `sklearn.mixture.GaussianMixture` or `sklearn.neighbors.KernelDensity`).\n",
    "\n",
    "If scorer is created based on string, tools must be passed explicitly. It can be done either with `set_tools` method (properly trained tools are required) or with `update_tools` method (just one bare estimator is needed, but training data must be provided too).\n",
    "\n",
    "Below cells show two equivalent ways of passing and setting `scorers`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sampler = CombinedSamplerFromPool(scorers=['confidence'])\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train_initial, y_train_initial)\n",
    "sampler.set_tools(tools=clf, scorer_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sampler = CombinedSamplerFromPool(scorers=['confidence'])\n",
    "sampler.update_tools(\n",
    "    X_train=X_train_initial,\n",
    "    y_train=y_train_initial,\n",
    "    est=RandomForestClassifier(),\n",
    "    scorer_id=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference between these two ways becomes more clear if tools must be something more complicated than just one estimator. For example, tools can be a committee."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sampler = CombinedSamplerFromPool(['divergence'])\n",
    "clf = RandomForestClassifier()\n",
    "committee = make_committee(clf, X_train_initial, y_train_initial)\n",
    "sampler.set_tools(committee, scorer_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sampler = CombinedSamplerFromPool(['divergence'])\n",
    "sampler.update_tools(X_train_initial, y_train_initial, RandomForestClassifier(), scorer_id=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So a sole estimator is passed only in the second case, whereas in the first case a committee of estimators is passed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One subtle issue is that formulas for confidence, margin, entropy, and divergence make rigorous sense only when predicted by classifier probabilities are true probabilities, i.e., numerical quantifications of uncertainty. However, some classifiers return just ordinal degrees of their internal assurance in class labels. Although such numbers are called probabilities, they are not probabilities. To go over this obstacle, it is supposed to calibrate predicted probabilities with Platt calibration or with isotonic regression. A class that can run any of these options is provided by `sklearn` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sampler = CombinedSamplerFromPool(['confidence'])\n",
    "clf = CalibratedClassifierCV(RandomForestClassifier())\n",
    "clf.fit(X_train_initial, y_train_initial)\n",
    "sampler.set_tools(clf, scorer_id=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An argument named `scorers_probabilities`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, go to `scorers_probabilities` argument. It must be a list of floats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epsilon_greedy_sampler = CombinedSamplerFromPool(\n",
    "    ['margin', 'random'], [0.95, 0.05]\n",
    ")\n",
    "epsilon_greedy_sampler.update_tools(\n",
    "    X_train_initial, y_train_initial, RandomForestClassifier(), scorer_id=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example, $\\varepsilon$-greedy strategy is implemented. After enough data are gathered, it still performs plenty of exploratory actions and this is a drawback of this strategy (at least in static environments). To fix it, gradual decrease of exploration probability is needed. It can be done by calls of `set_scorers_probabilities` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epsilon_greedy_sampler.set_scorers_probabilities([0.99, 0.01])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usage of a created instance is as simple as the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.49560098, -0.02856764],\n",
       "       [ 0.39816861, -0.40686834],\n",
       "       [ 0.21951536, -0.37881001]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = sampler.pick_new_objects(X_new, n_to_pick=3)\n",
    "X_new[indices, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Illustrative End-to-End Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here $\\varepsilon$-greedy strategy is compared with a benchmark based on random selection from a pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Random Forest usually does not warp probabilities.\n",
    "clf = RandomForestClassifier(n_estimators=20, random_state=361)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_n_points_to_explore = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scorers = ['margin', 'random']\n",
    "scorers_probabilities = [0.9, 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def report_accuracy_of_benchmark(\n",
    "        n_new_points: int,\n",
    "        clf: BaseEstimator,\n",
    "        X_train_initial: np.ndarray, y_train_inital: np.ndarray,\n",
    "        X_new: np.ndarray, y_new: np.ndarray,\n",
    "        X_hold_out: np.ndarray, y_hold_out: np.ndarray\n",
    "        ) -> float:\n",
    "    \"\"\"\n",
    "    Compute accuracy of approach where `n_new_points` objects\n",
    "    are picked from a pool at random, without active learning.\n",
    "    \"\"\"\n",
    "    X_train = np.vstack((X_train_initial, X_new[:n_new_points, :]))\n",
    "    y_train = np.hstack((y_train_initial, y_new[:n_new_points]))\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_hold_out_hat = clf.predict(X_hold_out)\n",
    "    return accuracy_score(y_hold_out, y_hold_out_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def report_accuracy_of_epsilon_greedy_strategy(\n",
    "        n_new_points: int,\n",
    "        clf: BaseEstimator,\n",
    "        scorers: List[str],\n",
    "        scorers_probabilities: List[float],\n",
    "        X_train_initial: np.ndarray, y_train_inital: np.ndarray,\n",
    "        X_new: np.ndarray, y_new: np.ndarray,\n",
    "        X_hold_out: np.ndarray, y_hold_out: np.ndarray\n",
    "        ) -> float:\n",
    "    \"\"\"\n",
    "    Compute accuracy of epsilon-greedy approach to active\n",
    "    learning.\n",
    "    \"\"\"\n",
    "    X_train = copy(X_train_initial)\n",
    "    y_train = copy(y_train_inital)\n",
    "    clf.fit(X_train, y_train)\n",
    "    sampler = CombinedSamplerFromPool(\n",
    "        scorers, scorers_probabilities\n",
    "    )\n",
    "    sampler.set_tools(clf, scorer_id=0)\n",
    "    for i in range(n_new_points):\n",
    "        indices = sampler.pick_new_objects(X_new, n_to_pick=1)\n",
    "        X_train = np.vstack((X_train, X_new[indices, :]))\n",
    "        y_train = np.hstack((y_train, y_new[indices]))\n",
    "        sampler.update_tools(X_train, y_train, scorer_id=0)\n",
    "        X_new = np.delete(X_new, indices, axis=0)\n",
    "        y_new = np.delete(y_new, indices)\n",
    "    clf = sampler.get_tools(0)\n",
    "    y_hold_out_hat = clf.predict(X_hold_out)\n",
    "    return accuracy_score(y_hold_out, y_hold_out_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93.703333333333276"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_scores = [\n",
    "    report_accuracy_of_benchmark(\n",
    "        n, clf,\n",
    "        X_train_initial, y_train_initial, X_new, y_new,\n",
    "        X_hold_out, y_hold_out\n",
    "    )\n",
    "    for n in range(1, max_n_points_to_explore + 1)\n",
    "]\n",
    "sum(benchmark_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96.066666666666777"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epsilon_greedy_scores = [\n",
    "    report_accuracy_of_epsilon_greedy_strategy(\n",
    "        n, clf, scorers, scorers_probabilities,\n",
    "        X_train_initial, y_train_initial, X_new, y_new,\n",
    "        X_hold_out, y_hold_out\n",
    "    )\n",
    "    for n in range(1, max_n_points_to_explore + 1)\n",
    "]\n",
    "sum(epsilon_greedy_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if draw_plots:\n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(benchmark_scores)\n",
    "    ax.plot(epsilon_greedy_scores, c='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To conclude, it can be seen that there is a noticable gain from usage of active learning instead of selecting objects randomly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customized Extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now suppose that any of pre-defined strings is not an appropriate choice for someone, because priorities of this user are unusual. Exploration is important, and another important thing is that it is more desirable to disclose the first class label than to disclose a label of second or third class. Moreover, sampling objects exactly near the decision boundary is not important. Sounds strange, does not it? However, it is easy to meet this specifications with `dsawl` package. Below, it is shown how to extend standard functionality with your own code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, define customized scoring function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_bayesian_scores(\n",
    "        predicted_probabilities: np.ndarray,\n",
    "        class_of_interest: int = 0\n",
    "        ) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Sample labels of objects from corresponding to them predicted\n",
    "    distributions and return binary indicators of having a label\n",
    "    of the class of interest.\n",
    "\n",
    "    :param predicted_probabilities:\n",
    "        predicted by the classifier probabilities of classes for\n",
    "        each of the new objects, shape = (n_new_objects, n_classes);\n",
    "        it is recommended to pass calibrated probabilities\n",
    "    :param class_of_interest:\n",
    "        ordinal number of class of interest, i.e., index of column\n",
    "        with this class probabilities\n",
    "    :return:\n",
    "        indicators that labels sampled from predicted distributions\n",
    "        are labels of the class of interest\n",
    "    \"\"\"\n",
    "    n_classes = predicted_probabilities.shape[1]\n",
    "    sampled_labels = []\n",
    "    for distribution in predicted_probabilities:\n",
    "        sampled_labels.append(np.random.choice(n_classes, p=distribution))\n",
    "    sampled_labels = np.array(sampled_labels)\n",
    "    result = (sampled_labels == class_of_interest).astype(int)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then make a scorer. A single classifier is involved, so it can be `UncertaintyScorerForClassification`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dsawl.active_learning.scorers import UncertaintyScorerForClassification\n",
    "\n",
    "scorer = UncertaintyScorerForClassification(\n",
    "    scoring_fn=compute_bayesian_scores\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now all is ready for applied code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sampler = CombinedSamplerFromPool(scorers=[scorer])\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train_initial, y_train_initial)\n",
    "sampler.set_tools(tools=clf, scorer_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.24940934,  0.57662896],\n",
       "       [-1.08723821,  1.14735078],\n",
       "       [-1.55920436,  0.7766194 ]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = sampler.pick_new_objects(X_new, n_to_pick=3)\n",
    "X_new[indices, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it is shown above, it is easy to extend active learning functionality."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsawl_env",
   "language": "python",
   "name": "dsawl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
